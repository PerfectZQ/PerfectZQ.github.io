---
layout: post
title: Flink
tag: Flink
---

## 参考
[Alibaba Blink](https://blog.csdn.net/qq_36852006/article/details/78217801)

## Flink
Flink 作为流计算引擎的优点

* low latency
* exactly once
* 流批统一
* 可以支持足够大数据量和复杂计算

不同于Spark，Flink是一个真正意义上的流计算引擎，和Storm类似，Flink是通过流水线数据传输实现低延迟的流处理；

Flink使用了经典的Chandy-Lamport算法，能够在满足低延迟和低failover开销的基础之上，完美地解决exactly once的目标；

如果要用一套引擎来统一流处理和批处理，那就必须以流处理引擎为基础。Flink还提供了SQL／tableAPI这两个API，为批和流在query层的统一又铺平了道路。因此Flink是最合适的批和流统一的引擎；

最后，Flink在设计之初就非常在意性能相关的任务状态state和流控等关键技术的设计，这些都使得用Flink执行复杂的大规模任务时性能更胜一筹。

## Flink Dataflow Programming Model
### API 抽象等级
Flink APIs 由低到高共抽象为四层

#### Low-Level building block - Stateful Stream Processing
最底层的抽象只提供有状态的流(stateful streaming)。通过把 process function 嵌入到 DataStream API 中。他允许用户自有处理来自一个或多个流的`event`，并使用一致的容错状态(consistent fault tolerant state)。除此之外，用户还可以注册事件时间(register event time)和处理时间回调(process time callbacks)，来实现复杂的计算。

#### Core APIs - DataStream/DataSet API
实际上大多数情况下不需要低级抽象，而是使用 Core APIs，如 DataStream API(有界/无界流)和 DataSet API(有界数据集)。这些 API 提供了用于数据处理的通用构建块，如各种形式的转换(transform)、连接(join)、聚合(aggregation)、窗口(window)、状态(state)等。

因为是低级 Process Functions 和 DataStream API 集成，因此只能对某些操作进行低级抽象。DataSet API 在有界数据集上提供了额外的 primitives，如循环/迭代。

#### Declarative DSL - Table API
Table API 是以表为中心的声明性 DSL，可以动态更改表(表示流时)。 Table API 遵循(扩展)关系模型：表附加了一个模式(类似于关系数据库中的表)，API 提供了类似的操作，例如 select，project，join，group-by，aggregate 等。Table API 程序以声明方式定义应该执行的逻辑操作，而不是用特定的代码实现具体的操作。尽管 Table API 可以通过各种类型的用户定义函数进行扩展，但它的表现力不如 Core API，但使用起来更简洁(编写的代码更少)。此外，Table API 在执行之前会先经过优化器，根据优化规则进行优化。

可以在表和 DataStream/DataSet 之间无缝转换，允许程序混合 Table API 以及 DataStream 和 DataSet API。

#### High-level Language - SQL
Flink 提供的最高级抽象是 SQL。这种抽象在语义和表达方面类似于 Table API，但是用 SQL 语句代表程序。 SQL 抽象与 Table API 紧密交互，SQL 查询可以在 Table API 中定义的表上执行。


## Deployment & Clusters

### Start a long-running Flink cluster on YARN
[Flink On YARN](https://ci.apache.org/projects/flink/flink-docs-release-1.7/ops/deployment/yarn_setup.html#run-a-flink-job-on-yarn)

#### Step1: 配置环境变量
Flink On YARN 需要`YARN_CONF_DIR`或者`HADOOP_CONF_DIR`环境变量去获取 YARN 和 HDFS 配置
```shell
$ vim ~/.bash_profile
# 如果不配置，可能会报各种 NoClassDefFoundError
export HAOODP_CLASSPATH=`hadoop classpath`
# 如果不配置，会有如下问题
# Setting HADOOP_CONF_DIR=/etc/hadoop/conf because no HADOOP_CONF_DIR was set.
# Neither the HADOOP_CONF_DIR nor the YARN_CONF_DIR environment variable is set. The Flink YARN Client needs one of these to be set to properly load the Hadoop configuration for accessing YARN.
export HADOOP_CONF_DIR="/etc/hadoop/conf"
export FLINK_HOME="/home/hdfs/flink-1.7.1"
export PATH=$PATH:$FLINK_HOME/bin
$ source ~/.bash_profile
```

#### Step2: 启动 Flink YARN-Session
一个 YARN-Session 会启动所有必要的 Flink Services(JobManager and TaskManager)，这样就可以提交程序到 cluster，每个 session 可以同时运行多个程序。

```shell
# 启动一个 yarn session
$ yarn-session.sh
Usage:
   Required
     -n,--container <arg>   Number of YARN container to allocate (=Number of Task Managers)
   Optional
     -D <arg>                        Dynamic properties, e.g: -Dtaskmanager.network.memory.min=536346624
     -d,--detached                   Start detached, 
     -jm,--jobManagerMemory <arg>    Memory for JobManager Container with optional unit (default: MB)
     -nm,--name                      Set a custom name for the application on YARN
     -q,--query                      Display available YARN resources (memory, cores)
     -qu,--queue <arg>               Specify YARN queue.
     -s,--slots <arg>                Number of slots per TaskManager
     -tm,--taskManagerMemory <arg>   Memory per TaskManager Container with optional unit (default: MB)
     -z,--zookeeperNamespace <arg>   Namespace to create the Zookeeper sub-paths for HA mode

# 10 task managers, 8GB memory, 32 processing slots(vcores)
# 注意不要超过 yarn 的实际资源，否则会报错
$ ./bin/yarn-session.sh -n 10 -tm 8192 -s 32

# attach to an existing YARN session
$ yarn-session.sh
Usage:
   Required
     -id,--applicationId <yarnAppId> YARN application Id     
# 连接到 application_1547006608740_4071 
$ ./bin/yarn-session.sh -id application_1547006608740_4071

# Stop the YARN session by stopping the unix process (using CTRL+C) or by entering ‘stop’ into the client.

# 如果不想让 Flink YARN client 一直运行，也可以启动分离(detached)的 YARN-Session。 
# 这种情况下，Flink YARN client 将仅向群集提交 Flink，然后自行关闭。
$ ./bin/yarn-session.sh -d
# 但是这样就无法使用 Flink 停止 YARN-Session 了，而是通过下面的命令停止
$ yarn application -kill application_1547006608740_4069
```

#### Step3: Submit job to Flink
[Flink Command-Line Interface](https://ci.apache.org/projects/flink/flink-docs-release-1.7/ops/cli.html)

```shell
./bin/flink
```

## Connectors
### Apache Kafka Connector
[Kafka Connector](https://ci.apache.org/projects/flink/flink-docs-release-1.7/dev/connectors/kafka.html)
```scala
// set up the streaming execution environment
val env = StreamExecutionEnvironment.getExecutionEnvironment
```