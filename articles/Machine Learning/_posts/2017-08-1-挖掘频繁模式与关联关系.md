---
layout: post
title: 挖掘频繁模式与关联关系
tag: Machine Learning
---
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

## 概念

　　**频繁模式**：模式可分为项集、子序列。假设数据库中有100条交易记录，其中80条交易记录中都包含牛奶和面包。牛奶和面包的组合就称为`项集`，频繁出现在数据库记录中的项集，就称为`频繁项集`。而如果项集是有先后顺序的，如先购买 PC 再购买键盘，那么 PC 和键盘的组合就称为`子序列`，同理频繁出现在数据库中的子序列就是`频繁子序列`。频繁项集和频繁子序列统称为频繁模式。

　　**关联规则**：在项集`A={面包,牛奶}`中，买面包的人也会买牛奶就是一对关联关系，关联关系表示为`面包=>牛奶[support=60%,confidence=80%]`。其中`support`是支持度，`confidence`是置信度。

　　**支持度**：在所有交易记录中，同时包含面包和牛奶的交易记录占交易记录总数的百分比，即 \\(P( 面包 \cup 牛奶 ) \\) 。

　　**置信度**：在所有交易记录中，包含面包的情况下包含牛奶的概率，即 \\( P( 牛奶 \| 面包 ) = \frac{ P( 面包 \cup 牛奶 ) }{ P( 面包 ) } \\)

　　**最小支持度阈值**：支持度超过最小支持度阈值的项集称为`频繁项集`。 

　　**最小置信度阈值**：满足最小支持度和最小置信度的关联规则成为`强关联规则`。

　　对于频繁项集挖掘，如果最小支持度计数设置的过小的话，会导致频繁项集过多，导致计算机无法处理。因为`一个频繁项集的子集肯定也是频繁项集`。一个长度为100的频繁项集，就会产生\\(C_{100}^{1}\\)个频繁一项集，\\(C_{100}^{2}\\)个频繁二项集... \\(C_{100}^{1} + C_{100}^{2} + ... + C_{100}^{100} = 2^{100}-1 \approx 1.27 * 10^{30} \\)个频繁子项集。因此提出了`闭频繁项集`和`极大频繁项集`的概念。

　　**闭频繁项集**：对于项集X和项集Y，如果X是Y的真子集，不存在真超项集Y和项集X的支持度计数相等。那么称项集X是`闭的`，如果项集X是频繁项集，则X称为闭频繁项集。

　　**极大频繁项集**：对于频繁项集X，X是Y的子集，不存在超项集Y是频繁项集，那么项集X称为极大频繁项集。

## Apriori
　　先验算法是发现频繁项集的最基本的算法，它通过限制候选产生发现频繁项集。
### 算法思想
　　先找出数据库中的所有频繁一项集`L1`，然后通过`L1`找出频繁二项集`L2`，以此类推，直到无法找到频繁k项集。
### 先验性质
　　**先验性质**：频繁项集的所有非空子集也一定是频繁的。对于一个非频繁项集I，添加项A到这个项集中，结果集\\(I \cup A\\)不可能比I更频繁，因此结果集也一定是非频繁的。
### 算法过程
　　找出每一个`Lk`就需要对数据库进行一次完整的扫描，但是基于先验性质可以压缩搜索空间。为了找出`Lk`，首先将`Lk-1`与自身连接产生候选k项集的集合。为了有效实现，Apriori算法默假定项集中的项是按字典顺序排好序的。这样，如果两个项集中的前`k-2`项是相同的，其他不同，则这两个项集是可连接的。例如，为了找出`L4`，项集`{I1,I2,I3}`和项集`{I1,I2,I4}`连接，产生的候选项集就是`{I1,I2,I3,I4}`。得到的候选项集不一定是频繁的，因此还需要扫描数据库，统计候选项集的支持度技术，确定是否是频繁项集，如果不是就凑候选项集集合中剔除。
## FP-growth
　　Apriori算法尽管压缩了候选项集的规模，但是仍然可能受两种开销影响。

1. 如果有10000个频繁一项集，就会产生\\( C_{10000}^{2} \\)个候选二项集
2. 可能需要重复扫描整个数据库，去匹配检查一个很大的候选集计算每个候选项集的支持度。

　　可以设计一种方法，挖掘全部频繁项集而无须这种昂贵的候选产生过程。这种方法就是**频繁模式增长(Frequent-Pattern Growth)**。它采取分治策略，将代表频繁项集的数据库压缩到一棵**频繁模式树**。

　　例如某数据库中有如下交易记录：

| 交易记录ID | 购买列表 |
| :-- | :-- |
| T1 | I1,I2,I5 |
| T2 | I2,I4 |
| T3 | I2,I3 |
| T4 | I1,I2,I4 |
| T5 | I1,I3 |
| T6 | I2,I3 |
| T7 | I1,I3 |
| T8 | I1,I2,I3,I5 |
| T9 | I1,I2,I3 |

　　数据库第一次扫描和Apriori算法相同，首先得到频繁一项集，并记录频繁项集的支持度计数，按项集的支持度计数从大到小排序。例如：设最小支持度计数为2，有`L1={{I2:7},{I1:6},{I3:6},{I4:2},{I5:2}}`。

　　然后开始构造FP树。首先创建树的根节点，初始化为`null`。开始第二次扫描数据库，将每条交易记录中的项都按`L1`中的次数排序，对于T1`{I1,I2,I5}`排序后就变成了`{I2,I1,I5}`。这就是FP-growth树的第一个分支。
![有帮助的截图]({{ site.url }}/assets/FP-growth1.png)

　　对于T2`{I2,I4}`，排序后依然是`{I2,I4}`。又添加一个分支，因为`I2`子节点已经存在了，因此合并。
![有帮助的截图]({{ site.url }}/assets/FP-growth2.png)

　　依次将各条排好序的交易记录添加到FP-growth树中。

| 交易记录ID | 购买列表 | 排序后 |
| :-- | :-- | :-- |
| T1 | I1,I2,I5 | I2,I1,I5 |
| T2 | I2,I4 | I2,I4 |
| T3 | I2,I3 | I2,I3 |
| T4 | I1,I2,I4 | I2,I1,I4 |
| T5 | I1,I3 | I1,I3 |
| T6 | I2,I3 | I2,I3 |
| T7 | I1,I3 | I1,I3 |
| T8 | I1,I2,I3,I5 | I2,I1,I3,I5 |
| T9 | I1,I2,I3 | I2,I1,I3 |

　　最终生成的FP-growth树如下：
![有帮助的截图]({{ site.url }}/assets/FP-growth3.png)

　　这样问题就由数据库频繁模式挖掘变成了FP树挖掘。首先，从长度为1的**后缀模式(节点)** 开始，构造它的**条件模式基**，即该节点的前缀路径上的节点组成的集合。按照`L1`倒序的顺序开始构造，`I5`的条件模式基就是`{{I2,I1,I3:1},{I2,I1:1}}`。然后将`I5`的条件模式基当作一个子数据库，构造`I5`的**条件FP树**。

　　首先计算`I5`的条件模式基构成的子数据库的`L1`(频繁一项集)，为`{I2:2,I1:2}`，得到后缀模式为`I5`的FP条件树如下。
![有帮助的截图]({{ site.url }}/assets/FP-growth4.png)

　　通过将条件模式树产生的所有频繁模式(频繁k项集)`{{I2:2}、{I1:2}、{I2:I1:2}}`与后缀模式`{I5}`分别进行**连接**进行**模式增长**，如下图所示。得到频繁模式`{I2,I5:2}、{I1,I5:2}、{I2,I1,I5:2}`。

　　`L1`中各项条件FP树挖掘如下表所示：

| 后缀模式 | 条件模式基 | 条件FP树 | 条件FP的频繁模式 | 模式增长 |
| :-- | :-- | :-- | :-- |
| I5 | {I2,I1:1}、{I2,I1,I3:1} | <I2:2,I1:2> | {I2:2}、{I1:2}、{I2,I1:2} | {I2,I5:2}、{I1,I5:2}、{I2,I1,I5:2} |
| I4 | {I2,I1:1}、{I2:1} | <I2:2> | {I2:2} | {I2,I4:2} |
| I3 | {I2,I1:2}、{I2:2}、{I1:2} | <I2:4,I1:2>,<I1:2> | {I2:4}、{I1:4}、{I2,I1:2} | {I2,I3:4}、{I1,I3:4}、{I2,I1,I3:2} |
| I1 | {I2:4} | <I2:4> | {I2:4} | {I2,I1:4} |
| I2 | 无 | 无 | 无 | 无 |

　　通过模式增长得到了所有**频繁k项集(k>=2)**，至此就得到了所有交易记录的频繁模式。FP-growth将发现长频繁项集(长度>=2)的问题转换成了在较小的子数据库中递归搜索较短频繁模式，然后连接后缀模式，得到长频繁模式。该方法显著降低了搜索开销。

## 由频繁项集产生关联规则
　　发现频繁项集后，就可以通过频繁项集直接产生强关联规则。对于频繁项集T的每个非空子集S，如果`support(T)/support(S)`大于最小置信度阈值，则就产生强规则`S=>(T-S)`
