---
layout: post
title: 准确率(Accuracy) 精确率(Precision) 召回率(Recall)和F1-Measure
tag: Machine Learning
---
## 先验知识
　　我们首先将数据的类别统一分为两类：**正类**和**负类**。例如：一个数据集中的数据一共有3类，小学生、中学生、高中生。我们的目标是预测小学生，那么标记为小学生的数据就是正类，标记为其他类型的数据都是负类。

　　数据有两种状态：**测试集数据**和**预测结果数据**。

　　对一批测试数据进行预测，结果可以分成四种。
* **TP(True Positive):** 原本是正类，预测结果为正类。(正确预测为正类)
* **FP(False Positive):** 原本是负类，预测结果为正类。(错误预测为正类)
* **TN(True Negative):** 原本是负类，预测结果为负类。(正确预测为负类)
* **FN(False Negative):** 原本是正类，预测结果为负类。(错误预测为负类)
## 准确率(Accuracy)
　　对于给定的测试数据集，分类器正确分类的样本数与样本总数之比，就称为准确率，即`(TP+TN)/(TP+TN+FP+FN)`
## 精确率(Precision)
　　在预测结果为正类的数据中，有多少数据被正确预测(原本就是正类)，即`TP/(TP+FP)`。

　　对应于检索中的**查准率**，`检索出相关文档数/检索出的文档总数`
## 召回率(Recall)
　　在测试集中为正类的数据中，有多少数据被正确预测(预测结果是正类)，即`TP/(TP+FN)`。

　　对应于检索中的**查全率**。`检索出相关文档数/文档库中相关文档总数`
## F1-Measure
　　精确率和召回率的调和平均值：`Accuracy * Precision * 2 / (Accuracy + Precision)`
## 总结
　　理论上，数据预测的准确率和召回率越接近1，说明预测模型的效果越好。但是实际中也不一定，取决于场景更倾向于哪一种。例如我们去某搜索引擎搜索XX病，一共返回了10条结果，其中5条广告，5条有用的相关信息，那么准确率就是`50%`，而后台数据库中一共就5条有用的相关信息，召回率却是`100%`，所以大家就认为这个搜索引擎也能凑合用。

　　区别精确率和召回率主要记住他们是分母不同就好了，召回率是对应测试集中的正类数据而言，而准确率是对应预测结果为正类的数据而言。