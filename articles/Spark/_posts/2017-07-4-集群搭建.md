---
layout: post
title: 集群搭建
tag: Spark
---

## Standalone模式部署
1. 去官网：http://spark.apache.org/downloads.html下载对应版本的Spark，解压。

2. 配置域名
```shell
vim /etc/hosts
# 将集群的所有节点都添加进去，各个节点都需要配置，否则会出现 net exception
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
10.4.121.202 s121202
10.4.121.203 s121203
10.4.121.204 s121204
10.4.121.205 s121205
10.4.121.206 s121206
```

3. 修改Spark配置文件
```shell
cd $SPARK_HOME/conf
cp spark-env.sh.template spark-env.sh
vi spark-env.sh
# 指定主节点host地址，端口号默认是7077
export SPARK_MASTER_HOST=s121202 # 前提是在hosts文件中指定了域名
# 指定特定的JDK，不配置则使用系统默认的jdk
export JAVA_HOME=/usr/java/jdk1.8.0_121
# 如果想通过域名地址而不是ip地址读取hdfs，则需要两个文件，/etc/hadoop/conf/下的hdfs-site.xml和core-site.xml
# 一般hadoop会配置HA策略，如果你访问hdfs的时候使用hdfs://10.4.121.79:8020/spark/logs，
# 当这个节点挂掉之后，HA策略会将主节点换成另一个IP，这样程序就会出现异常。
# 配置好后就可以在指定hdfs地址的时候使用域名访问，如 hdfs://hdp.neusoft.com/spark/logs
# 这样就算某个节点挂了，程序依然能正确的访问hdfs
# 方式1：
export HADOOP_CONF_DIR = /etc/hadoop/conf
# 方式2：将这两个文件拷贝到 $SPARK_HOME/conf/下
cp $HADOOP_HOME/conf/hdfs-site.xml $SPARK_HOME/conf/
cp $HADOOP_HOME/conf/core-site.xml $SPARK_HOME/conf/
```

4. 配置环境变量`SPARK_HOME`
```shell
vi ~/.bash_profile
SPARK_HOME=/opt/neu/spark-2.1.1-bin-hadoop2.6
export SPARK_HOME
PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
export PATH
```

5. 版本验证 `spark-shell`

6. 将从节点配置到slaves文件中
```shell
vi $SPARK_HOME/conf/slaves
# 添加下面的从节点
s121203
s121204
s121205
s121206
```

7. 配置Master无密钥登陆Slaves节点
```shell
# 记得将机器的防火墙关掉
service iptables stop
# 如果系统没有ssh，可能需要安装
yum -y install openssh-server
# 生成公钥 其中：-t 是类型 -P 是密码
ssh-keygen -t rsa -P "" 
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
# authorized_keys文件的权限为644
chmod 644 ~/.ssh/authorized_keys
# 刷新
sudo /etc/init.d/sshd reload
# ssh验证配置
ssh localhost
# 将Master节点的authorized_keys发送到所有的slaves节点
scp ~/.ssh/authorized_keys neu@s121203:~/.ssh/
# 或者，直接将.ssh文件夹发送到所有slaves节点
scp -rp ~/.ssh neu@s121203:~/
# 登陆验证
ssh s121203
# 如果免密登陆失败，可以通过下面的命令查看原因
ssh -vvv 目标机器ip
```

8. 将spark项目和hosts文件发送到各个子节点
```shell
scp -rp /opt/neu/spark-2.1.1-bin-hadoop2.6 neu@s121203:/opt/neu/
sudo scp /etc/hosts root@s121203:/etc/ 
```

9. 启动集群
```shell
cd $SPARK_HOME/
./sbin/start-all.sh
```

10. 查看启动情况
```shell
# 主节点可以看到Master进程，从节点可以看到Worker进程。
# 如果主节点也配置在了slaves文件中，那么主节点将会看到Master和Worker两个进程。
jps 
```