---
layout: post
title: 作业提交
tag: Spark
---

## spark各种模式下的提交方式以及配置参数说明
使用下面的命令查看对应版本的提交参数详细说明
```shell
spark-submit --help
```
### local模式下的提交模板
```shell
SPARK_HOME/bin/spark-submit \ # 执行spark-submit脚本
		# 指定提交jar包的主类
		--class com.neusoft.client.xxxxxxxx \ 
		# 4核cpu
		--master local[4] \ 
		# jar包路径，对于Python应用，在此位置传入一个.py文件并且以-py-files的方式搜索路径下加入Python.zip、.egg、.py文件
		/usr/zhangqiang/xxxx.jar 
		# 额外的参数，传递给main函数的args
		[application-arguments]
```
### standalone模式提交模板
```shell
# 在环境变量中配置了SPARK_HOME/bin后就可以直接调用此脚本
spark-submit \ 
		--class com.neusoft.SimpleApp \
		# spark集群master的地址
		--master spark://10.4.120.83:7077 \ 
		# 每个executor的内存大小
		--executor-memory 2G \	
		# 所有executors一共使用10个核
		--total-executor-cores 10 \ 
		/usr/zhangqiang/xxxx.jar
		[application-arguments]
```
### yarn模式提交模板
```shell
# 与standalone一一对应
spark-submit \
		--class com.neusoft.SimpleApp \
		# 默认是client模式，该集群的位置可以在HADOOP_CONF_DIR变量中找到
		--master yarn \
		--executor-memory 2G \
		--num-executors 10 \
		/usr/zhangqiang/xxxx.jar
		[application-arguments]
```
### yarn模式提交的两种方式
```shell
# 提交到yarn，默认以client模式提交
	# 客户端方式提交
		spark-submit --master yarn --deploy-mode client ...
	# 集群模式提交
		spark-submit --master yarn --deploy-mode cluster ...
```
## 导入第三方依赖
### 直接将依赖包打入提交的jar包里面
![有帮助的截图]({{ site.url }}/assets/idea_add_dependencies.png)

1. `Library Files` 这种方式是把`.class`文件打入到`artifact.jar`中，反编译后是这样的
![有帮助的截图]({{ site.url }}/assets/library_artifact.PNG)
2. `Extracted Directory` 是直接把`.jar`文件打入到`artifact.jar`中，相当于`maven-assembly`的`fat-jar`。如下：
![有帮助的截图]({{ site.url }}/assets/extracted_artifact.PNG)
### 指定 --jars
`--jars` 即 Spark Runtime Environment Property `saprk.jars`，指定一个以`,`分割的jar包文件列表。注意只能指定文件。
```shell
spark-submiy \
--class com.neusoft.SimpleApp \
--jars /opt/neu/jars/ojdbc.jar,/opt/neu/jars/hanlp-1.6.3.jar
```
### 

## 客户端模式和集群模式的最主要的区别
客户端模式比较适合开发调试，因为它是在同一物理位置（即同一网关）的服务器上提交应用程序，Driver直接在用户的spark-submit进程中启动，应用程序的输入和输出连接到控制台，能够快速的看到application的输出，比较适合开发和测试

如果应用程序是在远离Worker节点的某台机器上提交的，一般使用Cluster模式，这样可以使Drivers和Executors之间的网络延迟最小化，比较适合生产环境。

从深层次讲，他们的区别就是Application Master进程的区别，yarn-cluster模式下，driver运行在am（application master）中，他（driver）负责向yarn申请资源，并监督作业的运行状况，当用户提交了作业之后就可以关掉client了，作业会继续在yarn上运行。而client模式下am仅仅向yarn请求executor。client会和请求的container通信来调度他们的工作，也就是说不能关掉client。

总结：			

client模式下，am向yarn请求资源，client进行监督调度，所以spark yarn-client模式的配置都是以spark.am开头

cluster模式下，driver向yarn请求资源，并监督作业运行，所以spark yarn-cluster模式的配置以spark.driver开头
			
附：cluster模式的日志是下面这个样子的。
```console
17/04/07 18:27:10 INFO yarn.Client: Application report for application_1491557185266_0001 (state: RUNNING)
17/04/07 18:27:11 INFO yarn.Client: Application report for application_1491557185266_0001 (state: RUNNING)
17/04/07 18:27:12 INFO yarn.Client: Application report for application_1491557185266_0001 (state: RUNNING)
17/04/07 18:27:13 INFO yarn.Client: Application report for application_1491557185266_0001 (state: RUNNING)
17/04/07 18:27:14 INFO yarn.Client: Application report for application_1491557185266_0001 (state: RUNNING)
17/04/07 18:27:15 INFO yarn.Client: Application report for application_1491557185266_0001 (state: RUNNING)
```