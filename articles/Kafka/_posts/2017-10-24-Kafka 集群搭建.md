---
layout: post
title: Kafka 集群搭建
tag: Kafka
---

## 基本概念
* **Broker：** 服务代理。实质上就是kafka集群的一个物理节点。
* **Topic：** 特定类型的消息流。"消息"是字节的有效负载(payload)，话题是消息的分类的名或种子名
* **Partition：** Topic的子概念。一个Topic可以有多个Partition，但一个Partition只属于一个Topic。此外，Partition则是Consumer消费的基本单元。消费时。每个消费线程最多只能使用一个Partition。一个topic中partition的数量，就是每个user group中消费该topic的最大并行数量。
* **UserGroup：** 为了便于实现MQ中多播，重复消费等引入的概念。如果ConsumerA和ConsumerB属于同一个UserGroup，那么对于ConsumerA消费过的数据，ConsumerB就不能再消费了。也就是说，同一个user group中的consumer使用同一套offset
* **Offset：** Offset是专门对于Partition和UserGroup而言的，用于记录某个UserGroup在某个Partition中当前已经消费到达的位置。
* **Producer：** 生产者，能够发布消息到话题的任何对象。直接向某topic下的某partition发送数据。leader负责主备策略、写入数据、发送ack。
* **Consumer：** 消费者。可以订阅一个或者多个话题，通过fetch的方式从Broker中拉取数据，从而消费这些已经发布的信息的对象。kafka server不直接负责每个consumer消费到了哪，所以需要client和zk联合维护每个partition读到了哪里，即offset。

## 下载
[下载](https://www.apache.org/dyn/closer.cgi?path=/kafka/0.11.0.1/kafka_2.11-0.11.0.1.tgz) kafka_2.11-0.11.0.1.tgz

## 安装 

```shell
$ tar -zxvf kafka_2.11-0.11.0.1.tgz
```

## 配置、启动

```shell
$ cd kafka_2.11-0.11.0.1.tgz

# 启动zookeeper，如果集群中已经存在zookeeper可以忽略这一步
# 如果出现端口占用，可以修改zookeeper.properties文件中的默认端口号
$ bin/zookeeper-server-start.sh config/zookeeper.properties &

# 新添加两个kafka节点
$ cd config
$ cp server.properties server-1.properties 
$ cp server.properties server-2.properties 

# 修改 broker.id、port、datadir
$ vim server-1.properties 
    broker.id=1
    listeners=PLAINTEXT://10.4.121.218:9093
    log.dir=/tmp/kafka-logs-1
$ vim server-2.properties 
    broker.id=2
    listeners=PLAINTEXT://10.4.121.218:9094
    log.dir=/tmp/kafka-logs-2

# 启动kafka集群
$ bin/kafka-server-start.sh config/server.properties &
$ bin/kafka-server-start.sh config/server-1.properties &
$ bin/kafka-server-start.sh config/server-2.properties &

# 查看启动情况
$ jobs
# 启动情况如下 
[1]   Running                 cd .. && bin/zookeeper-server-start.sh config/zookeeper.properties &  (wd: /usr/zhangqiang/kafka_2.11-0.11.0.1/config)
[2]   Running                 bin/kafka-server-start.sh config/server.properties &
[3]-  Running                 bin/kafka-server-start.sh config/server-1.properties &
[4]+  Running                 bin/kafka-server-start.sh config/server-2.properties &
```
## 测试

```shell
# 创建一个有3个副本和一个分区的话题 my-replicated-topic 
$ bin/kafka-topics.sh --create \
--zookeeper 10.4.121.218:3333 \
--replication-factor 3 \
--partitions 1 \
--topic my-replicated-topic
# 注意：新版本用 --bootstrap-server 指定Kafka broker地址，--zookeeper 被弃用了)
# 因此所有 --zookeeper 都可以用 --bootstrap-server 替代，如下：
$ bin/kafka-topics.sh --create \
--bootstrap-server 10.4.121.218:9093,10.4.121.218:9094 \
--replication-factor 3 \
--partitions 1 \
--topic my-replicated-topic


# 查看broker的情况
$ bin/kafka-topics.sh --describe \
--zookeeper 10.4.121.218:3333 \
--topic my-replicated-topic
Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:
    # 配置情况：分区数据在节点broker.id=0、主节点是broker.id=1、副本集是broker.id=1,0,2、isr是broker.id=1,0,2
	Topic: my-replicated-topic	Partition: 0	Leader: 1	Replicas: 1,0,2	Isr: 1,0,2

# 发布消息到话题
$ bin/kafka-console-producer.sh \
--broker-list 10.4.121.218:9092 \
--topic my-replicated-topic
...
my test message 1
my test message 2
^C

# 消费消息
$ bin/kafka-console-consumer.sh \
--bootstrap-server 10.4.121.218:9092 \
--from-beginning \
--topic my-replicated-topic 
...
my test message 1
my test message 2
^C

# 测试集群容错，干掉主节点broker.id=1
$ ps aux|grep server-1.properties
root     11552  2.5  2.0 8028360 336356 pts/3  Sl   10:13   1:36 /usr/java/latest/bin/java......
$ kill -9 11552
$ bin/kafka-topic.sh --describe --zookeeper 10.4.121.218:3333 -topic my-replicated-topic
# 可以发现leader变成了broker.id=0，而且broker.id=1也不在Isr中了
Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:
	Topic: my-replicated-topic	Partition: 0	Leader: 0	Replicas: 1,0,2	Isr: 0,2
# 依然可以正常消费消息
$ bin/kafka-console-consumer.sh \
--bootstrap-server 10.4.121.218:9092 \
--from-beginning \
--topic my-replicated-topic
...
my test message 1
my test message 2
^C
# 重新启动broker.id=1
$ bin/kafka-server-start.sh config/server-1.properties &
$ bin/kafka-topic.sh --describe \
--zookeeper 10.4.121.218:3333 \
--topic my-replicated-topic
# Isr中又有了broker.id=1
Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:
	Topic: my-replicated-topic	Partition: 0	Leader: 0	Replicas: 1,0,2	Isr: 0,2,1
```

## Kafka Tools 管理工具
在`$KAFKA_HOME/bin`目录下，放着kafka常用的一些工具脚本，这些类的实现都是放在源码的`kafka/core/src/main/scala/kafka/tools/`路径下。

想查看这些脚本的使用参数说明的话，直接运行脚本。例如查看`kafka-topics.sh`的使用参数说明:
```shell
$ ./kafka-topics.sh
# 下面就会详细的参数介绍
Create, delete, describe, or change a topic.
Option                                   Description                            
------                                   -----------                            
--alter                                  Alter the number of partitions,        
                                           replica assignment, and/or           
                                           configuration for the topic.         
--config <String: name=value$            A topic configuration override for the 
                                           topic being created or altered.The   
                                           following is a list of valid         
......
```
常用脚本命令：
```shell
# 创建Topic
$ ./kafka-topics.sh --create \
--zookeeper 10.4.121.218:3333 \
--topic mytopic \
--replication-factor 1 \
--partitions 1 

# Topic列表
$ ./kafka-topics.sh --list \
--zookeeper 10.4.121.218:3333 

# 创建生产者
$ ./kafka-console-producer.sh \
--broker-list 10.4.121.218:9092 \
--topic mytopic

# 创建消费者
# 每次都是从开始位置消费，在生产环境下不建议这样使用。
$ ./kafka-console-consumer.sh \
--bootstrap-server 10.4.121.218:9092 \
--topic mytopic \
--from-beginning 
# 可以通过 --offset 指定开始消费的记录，可以指定一个非负整数，
# 或者`earliest`表示从第一条开始消费
# 或者`latest`表示从最后一条开始消费
$ ./kafka-console-consumer.sh \
--bootstrap-server 10.4.121.218:9092 \
--topic mytopic \
--offset earliest

# 查看指定topic
$ ./kafka-topics.sh --describe \
--zookeeper 10.4.121.218:3333 \
--topic mytopic

# 删除topic
# 需要配置`delete.topic.enable=true`
$ ./kafka-topics.sh --delete \
--zookeeper 10.4.121.218:3333 \
--topic mytopic
# 如果没有配置`delete.topic.enable=true`，那么此时并不是真正的删除，而只是把 topic 标记为 
# marked for deletion，还需要手动删除一下 Zookeeper 中的 Topic 记录
$ ./zkCli.sh -server 10.4.121.218:2181
$ /admin/delete_tpoics

# 显示出Consumer的Group、Topic、分区ID、分区对应已经消费的Offset、logSize大小，Lag以及Owner等信息。
# 使用脚本：kafka-consumer-offset-checker.sh
$ ./kafka-consumer-offset-checker.sh --broker-info \
--zookeeper 10.4.121.218:3333,10.4.121.202:3333,10.4.121.203:3333 \
--topic mytopic \
--group xb_id

# 有时候我们需要验证日志索引是否正确，或者仅仅想从log文件中直接打印消息。
# 使用脚本：kafka-run-class.sh
$ ./kafka-run-class.sh kafka.tools.DumpLogSegments 
$ ./kafka-run-class.sh kafka.tools.DumpLogSegments /nodedata/kafka/kafka-logs/xb_topic-0/00000000000000000033.log
$ ./kafka-run-class.sh kafka.tools.DumpLogSegments --print-data-log \
--files /nodedata/kafka/kafka-logs/xb_topic-0/00000000000000000033.log 

# 导出Zookeeper中Group相关的偏移量。有时候我们需要导出某个Consumer group各个分区的偏移量。
# 使用脚本：kafka-run-class.sh
$ ./kafka-run-class.sh kafka.tools.ExportZkOffsets
$ ./kafka-run-class.sh kafka.tools.ExportZkOffsets \
--group test_group \
--zkconnect 10.4.121.218:3333 \
--output-file ~/offset
$ vim ~/offset

# 这个工具主要作用是从一个Kafka集群里面读取指定Topic的消息，并将这些消息发送到其他集群的指定topic中。
# 使用脚本：./kafka-replay-log-producer.sh

# kafka-simple-consumer-shell.sh工具主要是使用Simple Consumer API从指定Topic的分区读取数据并打印在终端。
$ ./kafka-simple-consumer-shell.sh \
--broker-list 10.4.121.218:9092 \
--topic mytopic \
--partition 0

# kafka.tools.UpdateOffsetsInZK工具可以更新Zookeeper中指定Topic所有分区的偏移量，可以指定成 earliest或者latest
$ ./kafka-run-class.sh kafka.tools.UpdateOffsetsInZK

 

# 最后再注意kafka的启动和停止。
# 启动kafka： 
./kafka-server-start.sh /kafka/config/server.properties $/dev/null 2$&1 &
# 停止kafka： 直接kill掉进程就行。
$ ps aux | grep server-1.properties
root     11552  2.5  2.0 8028360 336356 pts/3  Sl   10:13   1:36 /usr/java/latest/bin/java......
$ kill -9  11552
```

## 通过 kafka connect 导入/导出数据
当需要从其他数据源导入kafka或者将kafka中的数据导入其他数据源，除了通过代码实现，还可以使用kafka connect来导入导出数据，它是一个可扩展的工具，通过运行connector，实现与外部系统交互的自定义逻辑。
```shell
# 造数据
$ echo -e "foo\nbar" > test.txt

# 在standalone模式下，启动两个connectors，需要配置三个配置文件。
# connect-standalone.properties配置kafka connect process，例如要连接到哪个broker，数据的序列化格式等。
# 其他的每个配置文件，都代表了要创建的每个connector，例如指定每个connector唯一的name，要实例化哪个connector class，和一些connector需要的其他的配置项。

# 修改 connect-standalone.properties
$ vim config/connect-standalone.properties
# These are defaults. This file just demonstrates how to override some settings.
bootstrap.servers=ambari0:9093

# The converters specify the format of data in Kafka and how to translate it into Connect data. Every Connect user will
# need to configure these based on the format they want their data in when loaded from or stored into Kafka
# org.apache.kafka.connect.converters.ByteArrayConverter
# org.apache.kafka.connect.converters.DoubleConverter
# org.apache.kafka.connect.converters.FloatConverter
# org.apache.kafka.connect.converters.IntegerConverter
# org.apache.kafka.connect.converters.LongConverter
# org.apache.kafka.connect.converters.ShortConverter
# org.apache.kafka.connect.json.JsonConverter
# org.apache.kafka.connect.storage.StringConverter
key.converter=org.apache.kafka.connect.storage.StringConverter
value.converter=org.apache.kafka.connect.storage.StringConverter

# Converter-specific settings can be passed in by prefixing the Converter's setting with the converter we want to apply
# it to
key.converter.schemas.enable=true
value.converter.schemas.enable=true

offset.storage.file.filename=/tmp/connect.offsets
# Flush much faster than normal, which is useful for testing/debugging
offset.flush.interval.ms=10000

# 导出 kafka 数据到 file
$ vim config/connect-file-sink.properties
name=kafka_to_file
connector.class=FileStreamSink
tasks.max=5
file=invert_index.txt
topics=invert_index
$ bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-sink.properties

# 导入 file 数据到 kafka
$ vim config/connect-file-source.properties
name=file_to_kafka
connector.class=FileStreamSource
tasks.max=5
file=invert_index.txt
topics=invert_index
$ bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties
```

## Kafka-Manager
[download](https://github.com/yahoo/kafka-manager)
```shell
# WARN: require jdk1.8，使用 jdk11 的时候会出现 NullPointerException

# 添加 sbt 镜像源，默认 jcenter 连不上
$ vim ~/.sbt/repositories
[repositories]
  local
  aliyun: http://maven.aliyun.com/nexus/content/groups/public/
  central: http://repo1.maven.org/maven2/
  
$ cd kafka-manager-master
# 编译为 zip
$ ./sbt clean dist
# 编译完的 zip 包在 ./target/universal/kafka-manager-1.3.3.22.zip

# 编译为 rpm
# 确认当前机器安装了 rpm(rpmbuild)，参考 https://github.com/yahoo/kafka-manager/issues/51
# 安装了 rpm 之后，rpmbuild 就可以使用了
$ brew install rpm
$ ./sbt rpm:packageBin
# 编译完成的 rpm 包在 ./target/rpm/RPMS/noarch/kafka-manager-1.3.3.22-1.noarch.rpm

# 安装，rpm 默认安装目录 /usr/share/kafka-manager
$ rpm -ivh kafka-manager-1.3.3.22-1.noarch.rpm

# 修改配置文件，添加 zk 地址，并注释掉 kafka-manager.zkhosts
$ vim /etc/kafka-manager/application.conf
ZK_HOSTS="hadoop1:2181,hadoop2:2181,hadoop3:2181"
#kafka-manager.zkhosts="kafka-manager-zookeeper:2181"

# 修改日志输出位置
$ vim /etc/kafka-manager/logger.xml
$ vim /etc/kafka-manager/log
# 把 ${application.home}/logs/application.log -> /var/log/kafka-manager/application.log
# 把 ${application.home}/logs/application.%d{yyyy-MM-dd}.log -> /var/log/kafka-manager/application.%d{yyyy-MM-dd}.log

# 设置开机启动
$ systemctl enable kafka-manager
```
