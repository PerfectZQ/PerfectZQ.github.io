---
layout: post
title: 集群搭建
tag: Kafka
---

## 基本概念
* **Broker：** 服务代理。实质上就是kafka集群的一个物理节点。
* **Topic：** 特定类型的消息流。"消息"是字节的有效负载(payload)，话题是消息的分类的名或种子名
* **Partition：** Topic的子概念。一个Topic可以有多个Partition，但一个Partition只属于一个Topic。此外，Partition则是Consumer消费的基本单元。消费时。每个消费线程最多只能使用一个Partition。一个topic中partition的数量，就是每个user group中消费该topic的最大并行数量。
* **UserGroup：** 为了便于实现MQ中多播，重复消费等引入的概念。如果ConsumerA和ConsumerB属于同一个UserGroup，那么对于ConsumerA消费过的数据，ConsumerB就不能再消费了。也就是说，同一个user group中的consumer使用同一套offset
* **Offset：** Offset是专门对于Partition和UserGroup而言的，用于记录某个UserGroup在某个Partition中当前已经消费到达的位置。
* **Producer：** 生产者，能够发布消息到话题的任何对象。直接向某topic下的某partition发送数据。leader负责主备策略、写入数据、发送ack。
* **Consumer：** 消费者。可以订阅一个或者多个话题，通过fetch的方式从Broker中拉取数据，从而消费这些已经发布的信息的对象。kafka server不直接负责每个consumer消费到了哪，所以需要client和zk联合维护每个partition读到了哪里，即offset。

## 下载
[下载](https://www.apache.org/dyn/closer.cgi?path=/kafka/0.11.0.1/kafka_2.11-0.11.0.1.tgz) kafka_2.11-0.11.0.1.tgz

## 安装 

```shell
> tar -zxvf kafka_2.11-0.11.0.1.tgz
```

## 配置、启动

```shell
> cd kafka_2.11-0.11.0.1.tgz

# 启动zookeeper，如果集群中已经存在zookeeper可以忽略这一步
# 如果出现端口占用，可以修改zookeeper.properties文件中的默认端口号
> bin/zookeeper-server-start.sh config/zookeeper.properties &

# 新添加两个kafka节点
> cd config
> cp server.properties server-1.properties 
> cp server.properties server-2.properties 

# 修改 broker.id、port、datadir
> vim server-1.properties 
    broker.id=1
    listeners=PLAINTEXT://10.4.121.218:9093
    log.dir=/tmp/kafka-logs-1
> vim server-2.properties 
    broker.id=2
    listeners=PLAINTEXT://10.4.121.218:9094
    log.dir=/tmp/kafka-logs-2

# 启动kafka集群
> bin/kafka-server-start.sh config/server.properties &
> bin/kafka-server-start.sh config/server-1.properties &
> bin/kafka-server-start.sh config/server-2.properties &

# 查看启动情况
> jobs
# 启动情况如下 
[1]   Running                 cd .. && bin/zookeeper-server-start.sh config/zookeeper.properties &  (wd: /usr/zhangqiang/kafka_2.11-0.11.0.1/config)
[2]   Running                 bin/kafka-server-start.sh config/server.properties &
[3]-  Running                 bin/kafka-server-start.sh config/server-1.properties &
[4]+  Running                 bin/kafka-server-start.sh config/server-2.properties &
```
## 测试

```shell
# 创建一个有3个副本和一个分区的话题 my-replicated-topic
> bin/kafka-topics.sh --create --zookeeper 10.4.121.218:3333 --replication-factor 3 --partitions 1 --topic my-replicated-topic

# 查看broker的情况
> bin/kafka-topics.sh --describe --zookeeper 10.4.121.218:3333 --topic my-replicated-topic
Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:
    # 配置情况：分区数据在节点broker.id=0、主节点是broker.id=1、副本集是broker.id=1,0,2、isr是broker.id=1,0,2
	Topic: my-replicated-topic	Partition: 0	Leader: 1	Replicas: 1,0,2	Isr: 1,0,2

# 发布消息到话题
> bin/kafka-console-producer.sh --broker-list 10.4.121.218:9092 --topic my-replicated-topic
...
my test message 1
my test message 2
^C

# 消费消息
> bin/kafka-console-consumer.sh --bootstrap-server 10.4.121.218:9092 --from-beginning --topic my-replicated-topic 
...
my test message 1
my test message 2
^C

# 测试集群容错，干掉主节点broker.id=1
> ps aux|grep server-1.properties
root     11552  2.5  2.0 8028360 336356 pts/3  Sl   10:13   1:36 /usr/java/latest/bin/java......
> kill -9 11552
> bin/kafka-topic.sh --describe --zookeeper 10.4.121.218:3333 -topic my-replicated-topic
# 可以发现leader变成了broker.id=0，而且broker.id=1也不在Isr中了
Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:
	Topic: my-replicated-topic	Partition: 0	Leader: 0	Replicas: 1,0,2	Isr: 0,2
# 依然可以正常消费消息
> bin/kafka-console-consumer.sh --bootstrap-server 10.4.121.218:9092 --from-beginning --topic my-replicated-topic
...
my test message 1
my test message 2
^C
# 重新启动broker.id=1
> bin/kafka-server-start.sh config/server-1.properties &
> bin/kafka-topic.sh --describe --zookeeper 10.4.121.218:3333 -topic my-replicated-topic
# Isr中又有了broker.id=1
Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:
	Topic: my-replicated-topic	Partition: 0	Leader: 0	Replicas: 1,0,2	Isr: 0,2,1
```

## Kafka Tools 管理工具
　　在`$KAFKA_HOME/bin`目录下，放着kafka常用的一些工具脚本，这些类的实现都是放在源码的`kafka/core/src/main/scala/kafka/tools/`路径下。

　　想查看这些脚本的使用参数说明的话，直接运行脚本。例如查看`kafka-topics.sh`的使用参数说明:
```shell
> ./kafka-topics.sh
# 下面就会详细的参数介绍
Create, delete, describe, or change a topic.
Option                                   Description                            
------                                   -----------                            
--alter                                  Alter the number of partitions,        
                                           replica assignment, and/or           
                                           configuration for the topic.         
--config <String: name=value>            A topic configuration override for the 
                                           topic being created or altered.The   
                                           following is a list of valid         
......
```
　　常用脚本命令：
```shell
# 创建Topic
> ./kafka-topics.sh --zookeeper 10.4.121.218:3333 --topic mytopic --replication-factor 1 --partitions 1 --create

# Topic列表
> ./kafka-topics.sh --zookeeper 10.4.121.218:3333 --list

# 创建生产者
> ./kafka-console-producer.sh --broker-list 10.4.121.218:9092 --topic mytopic

# 创建消费者
# 每次都是从开始位置消费，在生产环境下不建议这样使用。
> ./kafka-console-consumer.sh --zookeeper 10.4.121.218:3333 --topic mytopic --from-beginning 

# 查看指定topic
> ./kafka-topics.sh --describe --zookeeper 10.4.121.218:3333 --topic mytopic

# 删除topic
> ./kafka-topics.sh --delete --zookeeper 10.4.121.218:3333--topic mytopic

# 显示出Consumer的Group、Topic、分区ID、分区对应已经消费的Offset、logSize大小，Lag以及Owner等信息。
# 使用脚本：kafka-consumer-offset-checker.sh
> ./kafka-consumer-offset-checker.sh --zookeeper 10.4.121.218:3333,10.4.121.202:3333,10.4.121.203:3333 --topic mytopic --group xb_id --broker-info

# 有时候我们需要验证日志索引是否正确，或者仅仅想从log文件中直接打印消息。
# 使用脚本：kafka-run-class.sh
> ./kafka-run-class.sh kafka.tools.DumpLogSegments 
> ./kafka-run-class.sh kafka.tools.DumpLogSegments /nodedata/kafka/kafka-logs/xb_topic-0/00000000000000000033.log
> ./kafka-run-class.sh kafka.tools.DumpLogSegments --files /nodedata/kafka/kafka-logs/xb_topic-0/00000000000000000033.log --print-data-log

# 导出Zookeeper中Group相关的偏移量。有时候我们需要导出某个Consumer group各个分区的偏移量。
# 使用脚本：kafka-run-class.sh
> ./kafka-run-class.sh kafka.tools.ExportZkOffsets
> ./kafka-run-class.sh kafka.tools.ExportZkOffsets --group xb_id --zkconnect 10.4.121.218:3333,c13-139:2181,c13-141:2181 --output-file ~/offset
> vim ~/offset

# 这个工具主要作用是从一个Kafka集群里面读取指定Topic的消息，并将这些消息发送到其他集群的指定topic中。
# 使用脚本：./kafka-replay-log-producer.sh

# kafka-simple-consumer-shell.sh工具主要是使用Simple Consumer API从指定Topic的分区读取数据并打印在终端。
> ./kafka-simple-consumer-shell.sh --broker-list 10.4.121.218:9092 --topic mytopic --partition 0

# kafka.tools.UpdateOffsetsInZK工具可以更新Zookeeper中指定Topic所有分区的偏移量，可以指定成 earliest或者latest
> ./kafka-run-class.sh kafka.tools.UpdateOffsetsInZK

 

# 最后再注意kafka的启动和停止。
# 启动kafka： 
./kafka-server-start.sh /kafka/config/server.properties >/dev/null 2>&1 &
# 停止kafka： 直接kill掉进程就行。
> ps aux | grep server-1.properties
root     11552  2.5  2.0 8028360 336356 pts/3  Sl   10:13   1:36 /usr/java/latest/bin/java......
> kill -9  11552
```

## 通过 kafka connect 导入/导出数据
　　当需要从其他数据源导入kafka或者将kafka中的数据导入其他数据源，除了通过代码实现，还可以使用kafka connect来导入导出数据，它是一个可扩展的工具，通过运行connector，实现与外部系统交互的自定义逻辑。
```shell
# 造数据
> echo -e "foo\nbar" > test.txt

# 在standalone模式下，启动两个connectors，需要配置三个配置文件。
# connect-standalone.properties配置kafka connect process，例如要连接到哪个broker，数据的序列化格式等。
# 其他的每个配置文件，都代表了要创建的每个connector，例如指定每个connector唯一的name，要实例化哪个connector class，和一些connector需要的其他的配置项。
> bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties

```