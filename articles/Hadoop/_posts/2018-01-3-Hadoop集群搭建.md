---
layout: post
title: Hadoop 集群搭建
tag: Hadoop
---

## 搭建前的准备
　　本次搭建Hadoop版本是hadoop2.7.6-release，[点击下载安装包](http://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.7.6/hadoop-2.7.6.tar.gz)。

　　伪分布式集群搭建参考，[官方文档](http://hadoop.apache.org/docs/r3.0.0/hadoop-project-dist/hadoop-common/SingleCluster.html)

## 搭建过程
### 新建hadoop用户
```shell
useradd hadoop
# 为hadoop用户分配sudo权限
visudo
# 添加如下内容
hadoop ALL=(ALL)       NOPASSWD: ALL
# 设置hadoop密码
passwd hadoop
```
### 将下载好的hadoop-2.7.6.tar.gz包解压到`/home/hadoop/`。
```shell
su - hadoop 
tar -zxvf hadoop-2.7.6.tar.gz -C /home/hadoop/
```
### 配置环境变量。
```shell
vim ~/.bash_profile
export HADOOP_HOME=/home/hadoop/hadoop-2.7.6
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
source ~/.bash_profile

# 配置Hadoop环境变量
vim $HADOOP_HOME/etc/hadoop/hadoop-env.sh
export JAVA_HOME=/usr/java/jdk1.8.0_111/
```
### 修改 core-site.xml
`vim $HADOOP_HOME/etc/hadoop/core-site.xml`

```xml
<configuration>
    <!-- 指定主节点通信地址和端口 -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://192.168.10.145:9000</value>
    </property>
    <!-- 指定hadoop运行时产生的临时文件的存放路径 -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/home/hadoop/hadoop-2.7.6/tmp</value>
    </property>
</configuration>
```
### 修改 hdfs-site.xml
`vim $HADOOP_HOME/etc/hadoop/hdfs-site.xml`

```xml
<configuration>
    <!-- 设置namenode的http通讯地址 -->
    <property>
        <name>dfs.namenode.http-address</name>
        <value>192.168.10.145:50070</value>
    </property>
    <!-- 设置secondarynamenode的http通讯地址 -->
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>192.168.10.146:50070</value>
    </property>
    <!-- 设置namenode存放的路径 -->
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/home/hadoop/hadoop-2.7.6/namenode</value>
    </property>
    <!-- 设置hdfs副本数量 -->
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
    <!-- 设置datanode存放的路径 -->
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/home/hadoop/hadoop-2.7.6/datanode</value>
    </property>
</configuration>

```

### 修改 mapred-site.xml
　　首先需要执行`cp mapred-site.xml.template mapred-site.xml`，然后修改`mapred-site.xml`

```xml
<configuration>
    <!-- 通知框架MR使用YARN -->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

### 修改 yarn-site.xml
```xml
<configuration>
    <!-- 设置 ResourceManager 所在节点 -->
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>192.168.10.145</value>
    </property>
    <!-- 设置 reducer 取数据的方式 -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <!-- 指定 shuffle 处理类 -->
    <property>
         <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
         <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
    <!-- 配置环境变量白名单 -->
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
</configuration>
```

### 配置 Secondary NameNode
```shell
# 新建 masters 文件，将 Secondary NameNode 填写进去
vim masters
192.168.10.146
```

### 配置 DataNode
```shell
vim slaves
192.168.10.146
192.168.10.147
```

### 创建刚才配置文件中提到的文件夹
```shell
mkdir /home/hadoop/hadoop-2.7.6/tmp /home/hadoop/hadoop-2.7.6/namenode /home/hadoop/hadoop-2.7.6/datanode
```

### 配置到各个节点的 ssh。
```shell
ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
ssh-copy-id 192.168.10.145
ssh-copy-id 192.168.10.146
ssh-copy-id 192.168.10.147

# 测试
ssh 192.168.10.146
```

### 将 Hadoop 发送到各个节点
```shell
# 首先需要将环境变量文件发送给各个节点
scp ~/.bash_profile hadoop@192.168.10.146:~
# 记得到节点上刷新配置文件
source ~/.bash_profile

# 发送将配置完的Hadoop文件发送到各个节点
scp -rp /home/hadoop/hadoop-2.7.6 hadoop@192.168.10.146:~
```

### 格式化 FileSystem 并启动
　　Hadoop守护进程日志输出地址配置在`$HADOOP_LOG_DIR`，默认是`$HADOOP_HOME/logs`。

```shell
# 第一次启动需要格式化
hdfs namenode -format

# 启动hdfs
start-dfs.sh

# 在浏览器查看NameNode启动情况
http://localhost:9870/

# jps查看进程启动情况
18284 NameNode
18362 DataNode
18460 SecondaryNameNode
```

### 启动yarn
```shell
# 启动
sbin/start-yarn.sh
# 浏览器查看ResourceManager启动情况 
http://localhost:8088/
# jps 查看进程
14481 NodeManager
```

## 安装中出现的问题
### 在更换版本时 Incompatible clusterIDs
```console
java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-hadoop/dfs/data: namenode clusterID = CID-2814bb5f-3867-4f19-bc67-d0f3c3ca784e; datanode clusterID = CID-1bded296-4e6e-473c-91b6-6d3174f98926
```
很明显意思是namenode的clusterID和dataNode的clusterID不一致导致的。

```shell
# 关掉dfs
stop-dfs.sh
# 删掉有冲突的文件
rm -rf /tmp/hadoop-hadoop/
# 重新格式化即可
hdfs namenode -format
```

### Unable to load native-hadoop ...
```console
WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... 
using builtin-java classes where applicable
```
参考[这篇博客](http://blog.csdn.net/l1028386804/article/details/51538611)

### InconsistentFSStateException
```console
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: 
Directory /private/tmp/hadoop-despacito/dfs/name is in an inconsistent state: 
storage directory does not exist or is not accessible.
```

在启动Hadoop的时候会在`${hadoop.tmp.dir}`文件夹生成一堆文件，`${hadoop.tmp.dir}`属性配置在`conf/core-site.xml`中，默认是下面的样子。

```xml
<property>
   <name>hadoop.tmp.dir</name>
   <value>/private/tmp/hadoop-${user.name}</value>
   <description>A base for other temporary directories.</description>
</property>
```

如果tmp文件夹中的内容会被清理，Hadoop启动的时候不会恢复`${hadoop.tmp.dir}/dfs/name`这个文件夹，因此需要执行`hdfs namenode -format`重新生成这个文件夹就可以了。

