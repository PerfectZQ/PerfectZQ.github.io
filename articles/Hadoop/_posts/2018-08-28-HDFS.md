---
layout: post
title: HDFS
tag: Hadoop
---

## shell 命令
* [Hadoop Command Guide](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/CommandsManual.html)
* [Hadoop FileSystem Shell](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html)
* [HDFS Command Guide](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html)

### 查看 hdfs 全局和各个 datanode 磁盘使用情况
```shell
$ hdfs dfsadmin -report
Filesystem            Size   Used  Available  Use%
hdfs://hadoop3:8020  7.0 T  2.2 T      3.2 T   32%
[hdfs@hadoop1 ~]$ hdfs dfsadmin -report 
Configured Capacity: 7692823298048 (7.00 TB)
Present Capacity: 5998111523068 (5.46 TB)
DFS Remaining: 3554867421066 (3.23 TB)
DFS Used: 2443244102002 (2.22 TB)
DFS Used%: 40.73%
Under replicated blocks: 713
Blocks with corrupt replicas: 0
Missing blocks: 0
Missing blocks (with replication factor 1): 0

-------------------------------------------------
Live datanodes (4):

Name: 192.168.51.23:50010 (hadoop3)
Hostname: hadoop3
Decommission Status : Normal
Configured Capacity: 1923205824512 (1.75 TB)
DFS Used: 653372555985 (608.50 GB)
Non DFS Used: 396316900655 (369.10 GB)
DFS Remaining: 871685526740 (811.82 GB)
DFS Used%: 33.97%
DFS Remaining%: 45.32%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 14
Last contact: Wed May 29 16:14:10 CST 2019
Last Block Report: Wed May 29 13:44:34 CST 2019


Name: 192.168.51.21:50010 (hadoop1)
Hostname: hadoop1
Decommission Status : Normal
Configured Capacity: 1923205824512 (1.75 TB)
DFS Used: 679353677508 (632.70 GB)
Non DFS Used: 444841732412 (414.29 GB)
DFS Remaining: 797045355822 (742.31 GB)
DFS Used%: 35.32%
DFS Remaining%: 41.44%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 16
Last contact: Wed May 29 16:14:13 CST 2019
Last Block Report: Wed May 29 13:48:37 CST 2019


Name: 192.168.51.22:50010 (hadoop2)
Hostname: hadoop2
Decommission Status : Normal
Configured Capacity: 1923205824512 (1.75 TB)
DFS Used: 424732104669 (395.56 GB)
Non DFS Used: 412954871843 (384.59 GB)
DFS Remaining: 1083688006868 (1009.26 GB)
DFS Used%: 22.08%
DFS Remaining%: 56.35%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 14
Last contact: Wed May 29 16:14:12 CST 2019
Last Block Report: Wed May 29 15:06:18 CST 2019


Name: 192.168.51.24:50010 (hadoop4)
Hostname: hadoop4
Decommission Status : Normal
Configured Capacity: 1923205824512 (1.75 TB)
DFS Used: 685785763840 (638.69 GB)
Non DFS Used: 434703093760 (404.85 GB)
DFS Remaining: 802448531636 (747.34 GB)
DFS Used%: 35.66%
DFS Remaining%: 41.72%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 6
Last contact: Wed May 29 16:14:12 CST 2019
Last Block Report: Wed May 29 13:13:36 CST 2019
```

### 清理回收站
```shell
# 从 trash 目录中永久删除早于保留阈值的检查点中的文件，并创建新的检查点。
# 创建检查点时，垃圾箱中最近删除的文件将移动到检查点下。 早于`fs.trash.interval`
# 的检查点中的文件将在下次调用 -expunge 命令时被永久删除。
# 受影响的目录是当前用户 /user/{current_user}/.Trash 目录
$ hadoop fs -expunge
```

### 修改文件副本数量
```shell
# 首先 dfs.replication 这个参数是个 client 参数，即 node level 参数。需要在每台 datanode 上设置，默认为 3
# 可以在上传文件的同时指定创建的副本数，如果你只有 3 个datanode，但是你却指定副本数为4，是不会生效的，因为每个 
# datanode 上只能存放一个副本。
$ hadoop fs -D dfs.replication=1 -put 70M logs/2

# 一个文件，上传到 hdfs 上时指定的是几个副本就是几个。即便你修改了 dfs.replication 副本数，对已经上传了的文件
# 也不会起作用，但可以通过命令来更改已经上传的文件的副本数
# -w 表示等待副本操作结束才退出命令，这可能需要很长时间
# -R 目录内递归生效，为了兼容，其实默认就是该效果
# 如果指定的 path 是个目录则递归的更改该目录下所有文件的副本数
$ hadoop fs -setrep [-R] [-w] <numReplicas> <path>
```

### 查看指定路径 hdfs 的副本情况
```shell
$ hdfs fsck -locations <path>
 Total size:    583921551399 B (Total open files size: 450 B)
 Total dirs:    56028
 Total files:   244955
 Total symlinks:                0 (Files currently being written: 6)
 Total blocks (validated):      234496 (avg. block size 2490113 B) (Total open file blocks (not validated): 5)
 Minimally replicated blocks:   234496 (100.0 %)
 Over-replicated blocks:        0 (0.0 %)
 Under-replicated blocks:       481 (0.20512077 %)
 Mis-replicated blocks:         0 (0.0 %)
 Default replication factor:    3
 Average block replication:     3.002051
 Corrupt blocks:                0
 Missing replicas:              1476 (0.20922963 %)
 Number of data-nodes:          4
 Number of racks:               1
FSCK ended at Thu May 16 14:51:42 CST 2019 in 3711 milliseconds

# 查看文件(注意是文件，文件夹看不到)的副本数，这里可以看到副本数是 3
$ hadoop fs -ls /apps/hive/warehouse/du.db/indices/dt=2017-09-01
-rw-r--r--   3 root hadoop   72395047 2019-05-15 15:26 /apps/hive/warehouse/du.db/indices/dt=2017-09-01/part-00919-7aef8d30-1b51-4ad6-9336-81a39870aeba.c000.snappy.orc
```

## HDFS 集群优化
### Linux 文件系统
推荐使用`xfs`或`ext4`，centos7.0开始默认文件系统是`xfs`，centos6是`ext4`，centos5是`ext3`，`ext3`和`ext4`的最大区别在于，`ext3`在`fsck`时需要耗费大量时间，文件越多，时间越长。而`ext4`在`fsck`时用的时间会少很多。

`ext4(Fourth Extended Filesystem, 第四代扩展文件系统)`是 Linux 系统下的日志文件系统，是`ext3`的后继版本。`ext4`的文件系统容量达到`1EB`，最大单以文件容量则达到`16TB`，这是一个非常大的数字了。对一般的台式机和服务器而言，这可能并不重要，但对于大型磁盘阵列的用户而言，这就非常重要了。`ext3`目前只支持`32000`个子目录，而`ext4`取消了这一限制，理论上支持无限数量的子目录。`Ext`家族是 Linux 支持度最广、最完整的文件系统，当我们格式化磁盘后，就已经为我们规划好了所有的`inode/block/metadata`等数据，这样系统可以直接使用，不需要再进行动态的配置，这也是它的优点，不过这也是它最显著的缺点，磁盘容量越大，格式化越慢，centos7.x 已经选用`xfs`作为默认文件系统，`xfs`是一种适合大容量磁盘和处理巨型文件的文件系统。

`xfs`是一种非常优秀的日志文件系统，它是SGI公司设计的。`xfs`被称为业界最先进的、最具可升级性的文件系统技术。`xfs`是一个64位文件系统，最大支持`8EB - 1Byte`的单个文件系统，实际部署时取决于宿主操作系统的最大块限制。对于一个 32 位 Linux 系统，文件和文件系统的大小会被限制在`16TB`。`xfs`在很多方面确实做的比`ext4`好，`ext4`受限制于磁盘结构和兼容问题，可扩展性(scalability)确实不如`xfs`，另外`xfs`经过很多年发展，各种锁的细化做的也比较好。但是`xfs`文件系统不能缩小，当删除大量文件时性能会下降。
