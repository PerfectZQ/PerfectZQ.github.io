---
layout: post
title: HDFS
tag: Hadoop
---

## shell 命令
* [Hadoop Command Guide](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/CommandsManual.html)
* [Hadoop FileSystem Shell](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html)
* [HDFS Command Guide](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html)

```shell
# 查看磁盘使用情况
$ hdfs dfsadmin -report

# 首先 dfs.replication 这个参数是个 client 参数，即 node level 参数。需要在每台 datanode 上设置，默认为 3
# 可以在上传文件的同时指定创建的副本数，如果你只有 3 个datanode，但是你却指定副本数为4，是不会生效的，因为每个 
# datanode 上只能存放一个副本。
$ hadoop fs -D dfs.replication=1 -put 70M logs/2

# 一个文件，上传到 hdfs 上时指定的是几个副本就是几个。即便你修改了 dfs.replication 副本数，对已经上传了的文件
# 也不会起作用，但可以通过命令来更改已经上传的文件的副本数
$ hadoop fs -setrep -R 3 /

# 查看当前 hdfs 的副本数
$ hdfs fsck -locations
 Total size:    583921551399 B (Total open files size: 450 B)
 Total dirs:    56028
 Total files:   244955
 Total symlinks:                0 (Files currently being written: 6)
 Total blocks (validated):      234496 (avg. block size 2490113 B) (Total open file blocks (not validated): 5)
 Minimally replicated blocks:   234496 (100.0 %)
 Over-replicated blocks:        0 (0.0 %)
 Under-replicated blocks:       481 (0.20512077 %)
 Mis-replicated blocks:         0 (0.0 %)
 Default replication factor:    3
 Average block replication:     3.002051
 Corrupt blocks:                0
 Missing replicas:              1476 (0.20922963 %)
 Number of data-nodes:          4
 Number of racks:               1
FSCK ended at Thu May 16 14:51:42 CST 2019 in 3711 milliseconds

# 查看文件(注意是文件，文件夹看不到)的副本数，这里可以看到副本数是 3
$ hadoop fs -ls /apps/hive/warehouse/du.db/indices/dt=2017-09-01
-rw-r--r--   3 root hadoop   72395047 2019-05-15 15:26 /apps/hive/warehouse/du.db/indices/dt=2017-09-01/part-00919-7aef8d30-1b51-4ad6-9336-81a39870aeba.c000.snappy.orc
```