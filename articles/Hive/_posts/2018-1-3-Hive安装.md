---
layout: post
title: Hive安装
tag: Hive
---

## 搭建前的准备
　　首先得搭建好Hadoop，可以参考[之前的博客](https://arch-long.cn/articles/hadoop/Hadoop%E6%90%AD%E5%BB%BA.html)

　　Hive版本：apache-hive-2.3.2-bin.tar.gz。[点击下载](http://mirrors.tuna.tsinghua.edu.cn/apache/hive/)。

　　参考[官方手册](https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-InstallationandConfiguration)

　　参考博客[Hive的几种内置服务](http://blog.csdn.net/gamer_gyt/article/details/52062460)
## 安装过程
### 解压
```shell
tar -xzvf hive-2.3.2.tar.gz -C /home/hadoop/
```
### 配置环境变量
　　PATH 环境变量中必须有 HADOOP_HOME
```shell
vim ~/.bash_profile
export HIVE_HOME=/home/hadoop/apache-hive-2.3.2-bin
export PATH=$HIVE_HOME/bin:$PATH
source ~/.bash_profile
```
### 修改配置文件
hive-env.sh ：

```shell
cd $HIVE_HOME/conf/
cp hive-env.sh.template hive-env.sh
vim hive-env.sh
# 修改内容如下：
```

hive-site.xml :

```shell
# Hive 默认从 conf/hive-default.xml 中读取配置项，用户可以通过 conf/hive-site.xml 覆盖默认的配置。
# Hive 配置文件夹可以通过 $HIVE_CONF_DIR 来修改，默认是 $HIVE_HOME/conf/
# === 方式1 ===
cp hive-default.xml.template hive-default.xml
# 但是这样做有时候会出现问题：
# ...
# 原因是 Hive 找不到 ${system:java.io.tmpdir}，${system:user.name}
# 解决方案：
mkdir /home/hadoop/hive-2.3.2/tmp
vim hive-default.xml
# 将所有 ${system:java.io.tmpdir} 替换成 /home/hadoop/hive-2.3.2/tmp/
# 将所有 ${system:user.name} 改成 ${user.name}
# === 方式2 ===
# 新建新的 hive-site.xml，当然需要包含 xml 命名空间和 configuration 标签
vim hive-site.xml
```

　　不管方式1还是方式2都要添加如下内容

```xml
<configuration>
    <property>
        <name>hive.exec.scratchdir</name>
        <value>/home/hadoop/apache-hive-2.3.2-bin/tmp</value>
    </property>
    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>/home/hadoop/apache-hive-2.3.2-bin/warehouse</value>
    </property>
    <property>
        <name>hive.querylog.location</name>
        <value>/home/hadoop/apache-hive-2.3.2-bin/log</value>
    </property>
    <!-- 配置 Metastore 官网配置的是 derby，这里配置 mysql -->
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <!-- hive 是 mysql 数据库的名称 -->
        <value>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&amp;characterEncoding=UTF-8&amp;useSSL=false</value>
    </property>
    <property>
        <!-- 数据库驱动类 -->
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
    </property>
    <property>
        <!-- 数据库用户名 -->
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
    </property>
    <property>
        <!-- 数据库密码 -->
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>hive</value>
    </property>
</configuration>
```
### 初始化
```shell
schematool -dbType mysql -initSchema
```
## Hive 的内置服务
```shell
# 查看 hive 内置服务
hive --service help
```
显示如下：
```console
Usage ./hive <parameters> --service serviceName <service parameters>
# hive的所有服务/组件
Service List: beeline cleardanglingscratchdir cli hbaseimport hbaseschematool help hiveburninclient hiveserver2 hplsql jar lineage llap llapdump llapstatus metastore metatool orcfiledump rcfilecat schemaTool version 
Parameters parsed:
  --auxpath : Auxiliary jars 
  --config : Hive configuration directory
  --service : Starts specific service/component. cli is default
Parameters used:
  HADOOP_HOME or HADOOP_PREFIX : Hadoop install directory
  HIVE_OPT : Hive options
# 查看某个服务/组件的详细用法
For help on a particular service:
  ./hive --service serviceName --help
Debug help:  ./hive --debug --help
```
## 启动
Hive 的启动方式大概可以分为三类：CLI(Command Line Interface)、HWI(Hive Web Interface)、HiveServer
### CLI
### HWI
### HiveServer