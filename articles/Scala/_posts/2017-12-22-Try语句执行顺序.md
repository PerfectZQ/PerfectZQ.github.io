---
layout: post
title: Scala知识点整理
tag: Scala
---

```scala
val sparkSession = SparkSession.builder().master("local[2]").appName("test").getOrCreate()
val snRDD = sparkSession.sparkContext.makeRDD(Array("Just for Test")).cache
snRDD
  .repartition(1)
  .mapPartitions[String] { snOfPartition =>
  try {
    println(s"try func ...")
    val result = snOfPartition.toArray
      .groupBy { x =>
        println(s"try - groupBy func ...")
        x
      }
      .toIterator // groupBy 得到的 immutable.Map[String,String] 对象被调用。执行 groupBy 中的代码。
      .map { x =>
        println(s"try - map func ...")
        x
      }
      .flatMap { x =>
        println(s"try - flatMap func ...")
        Array("Just for test.")
      }
    result // return 语句需要调用 flatMap 操作返回的对象，此刻去执行 map 和 flatMap 中的代码。而 return 语句是在 finally 块之后执行的。
  } finally {
    println(s"finally func ...")
  }
}
  .collect()
```
　　这段代码的执行顺序如下
```console
try func ...
try - groupBy func ...
finally func ...
try - map func ...
try - flatMap func ...
```
　　将代码改成
```scala
val sparkSession = SparkSession.builder().master("local[2]").appName("test").getOrCreate()
val snRDD = sparkSession.sparkContext.makeRDD(Array("Just for Test")).cache
snRDD
  .repartition(1)
  .mapPartitions[String] { snOfPartition =>
  try {
    println(s"try func ...")
    val result = snOfPartition.toArray
      .groupBy { x =>
        println(s"try - groupBy func ...")
        x
      }
      .map { x =>
        println(s"try - map func ...")
        x
       }
      .flatMap { x =>
        println(s"try - flatMap func ...")
        Array("Just for test.")
      }
      .toIterator
    result 
  } finally {
    println(s"finally func ...")
  }
}
  .collect()
```
　　执行顺序如下
```console
try func ...
try - groupBy func ...
try - map func ...
try - flatMap func ...
finally func ...
```
　　总结：
* scala中的算子操作是lazy操作，只有当返回的集合对象被调用(执行，赋值不算)时，才会去执行算子当中的代码。
* Spark中的算子是触发Action操作的时候，才会去执行。